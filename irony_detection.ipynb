{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Baseline F1-score Task A: 0.626344086022\n",
    "One way to improve baseline: using emoticon-feature (though according to Barbieri, Saggion 2014 this feature is more effective with Humour corpora, because \"ironic authors usually avoid emoticons and leave words to be the central thing\").\n",
    "\n",
    "Opinion lexicon: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import logging\n",
    "import codecs\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_dict(fz):\n",
    "    z = {}\n",
    "    with open(fz, 'rt', encoding=\"utf-8\") as data_in:\n",
    "        for line in data_in:\n",
    "            emot = line.split()[0]\n",
    "            label = line.split()[1]\n",
    "            z[emot] = label\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polarity(fk):\n",
    "    arr = []\n",
    "    with open(fk, 'rt', encoding=\"utf-8\") as data_in:\n",
    "        try:\n",
    "            for line in data_in:\n",
    "                line = line.strip(\"\\n\")\n",
    "                if fk.endswith(\"positive-words.txt\"):\n",
    "                    arr.append(line)\n",
    "                else:\n",
    "                    arr.append(line)\n",
    "        except:\n",
    "            pass\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dataset(fp):\n",
    "    y = []\n",
    "    corpus = []\n",
    "    with open(fp, 'rt', encoding=\"utf-8\") as data_in:\n",
    "        for line in data_in:\n",
    "            if not line.lower().startswith(\"tweet index\"):\n",
    "                line = line.rstrip()\n",
    "                label = int(line.split(\"\\t\")[1])\n",
    "                tweet = line.split(\"\\t\")[2]\n",
    "                words_tweet = tweet.split()\n",
    "                for item in words_tweet:\n",
    "                    for key, value in dic.items():\n",
    "                        if item == key:\n",
    "                            tweet = tweet.replace(item, value)\n",
    "                corpus.append(tweet)\n",
    "                y.append(label)\n",
    "    return corpus, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(corpus):\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True).tokenize\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"unicode\", analyzer=\"word\", tokenizer=tokenizer, stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(corpus).toarray()\n",
    "    i = 0\n",
    "    while i < len(corpus):\n",
    "        tweet = corpus[i].split()\n",
    "        for word in tweet:\n",
    "            if word in neg and \"happy\" in tweet:\n",
    "                X[i] = X[i] * (-1)\n",
    "            if word in pos and \"sad\" in tweet:\n",
    "                X[i] = X[i] * (-1)\n",
    "        i +=1\n",
    "    X = sparse.csr_matrix(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1923], [1, 1911]]\n",
      "F1-score Task A 0.630283574104\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    EMOTICS_FZ = \"C:/Users/1/Desktop/emoticons.txt\"\n",
    "    dic = emoticons_dict(EMOTICS_FZ)\n",
    "    \n",
    "    LIST_POS = \"C:/Users/1/Desktop/positive-words.txt\"\n",
    "    pos = polarity(LIST_POS)\n",
    "    \n",
    "    LIST_NEG = \"C:/Users/1/Desktop/negative-words.txt\"\n",
    "    neg = polarity(LIST_NEG)\n",
    "    \n",
    "    DATASET_FP = \"C:/Users/1/Desktop/taskA.txt\"\n",
    "    \n",
    "    TASK = \"A\"\n",
    "    FNAME = 'C:/Users/1/Desktop/predictions-task' + TASK + '.txt'\n",
    "    PREDICTIONSFILE = open(FNAME, \"w\")\n",
    "    \n",
    "    K_FOLDS = 10\n",
    "    CLF = LinearSVC()\n",
    "\n",
    "    corpus, y = parse_dataset(DATASET_FP)\n",
    "    X = featurize(corpus)\n",
    "\n",
    "    class_counts = np.asarray(np.unique(y, return_counts=True)).T.tolist()\n",
    "    print (class_counts)\n",
    "    \n",
    "    predicted = cross_val_predict(CLF, X, y, cv=K_FOLDS)\n",
    "    \n",
    "    if TASK.lower() == 'a':\n",
    "        score = metrics.f1_score(y, predicted, pos_label=1)\n",
    "    elif TASK.lower() == 'b':\n",
    "        score = metrics.f1_score(y, predicted, average=\"macro\")\n",
    "    print (\"F1-score Task\", TASK, score)\n",
    "    for p in predicted:\n",
    "        PREDICTIONSFILE.write(\"{}\\n\".format(p))\n",
    "    PREDICTIONSFILE.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
