{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "import wikipedia as wiki\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove2word2vec(glove_input_file = \"D:/glove.6B/glove.6B.300d.txt\", word2vec_output_file = \"D:/gensim_glove_vectors.txt\")\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"D:/gensim_glove_vectors.txt\", binary=False)\n",
    "glove_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet \n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wn_similarity(x, y):\n",
    "    for sense1, sense2 in product(x, y):\n",
    "        d = wordnet.wup_similarity(sense1, sense2)\n",
    "        if d != None:\n",
    "            wn_sim = d\n",
    "        else:\n",
    "            wn_sim = 0\n",
    "    return wn_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#wv-wk\n",
    "dataset = open(\"C:/Users/1/Desktop/validation.txt\", encoding = 'utf-8').readlines()\n",
    "K, m = [], []\n",
    "for d in range(len(dataset)):\n",
    "    try:\n",
    "        lin = dataset[d].strip().split(',')\n",
    "            \n",
    "        target_sim = glove_model.similarity(lin[0], lin[2])\n",
    "        comp_sim = glove_model.similarity(lin[1], lin[2])\n",
    "        targ_comp_sim = glove_model.similarity(lin[0], lin[1])\n",
    "            \n",
    "        try:\n",
    "            sum_lin_0 = wiki.summary(lin[0])\n",
    "        except wiki.exceptions.DisambiguationError as e:\n",
    "            sum_lin_0 = wiki.summary(e.options[0])\n",
    "        try:\n",
    "            sum_lin_1 = wiki.summary(lin[1])\n",
    "        except wiki.exceptions.DisambiguationError as e:\n",
    "            sum_lin_1 = wiki.summary(e.options[0])\n",
    "        lin_0_wiki = len(re.findall(lin[2], sum_lin_0))\n",
    "        lin_1_wiki = len(re.findall(lin[2], sum_lin_1))\n",
    "                \n",
    "        K.append((target_sim, comp_sim, target_sim-comp_sim, targ_comp_sim, lin_0_wiki, lin_1_wiki, lin_0_wiki-lin_1_wiki))\n",
    "        m.append(lin[3])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2696\n"
     ]
    }
   ],
   "source": [
    "print (len(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_train = K[0:1696]\n",
    "m_train = m[0:1696]\n",
    "K_test = K[1696:]\n",
    "m_test = m[1696:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#+wordnet\n",
    "dataset = open(\"C:/Users/1/Desktop/validation.txt\", encoding = 'utf-8').readlines()\n",
    "X, y = [], []\n",
    "for d in range(len(dataset)):\n",
    "    try:\n",
    "        lin = dataset[d].strip().split(',')\n",
    "            \n",
    "        target_sim = glove_model.similarity(lin[0], lin[2])\n",
    "        comp_sim = glove_model.similarity(lin[1], lin[2])\n",
    "        targ_comp_sim = glove_model.similarity(lin[0], lin[1])\n",
    "            \n",
    "        try:\n",
    "            sum_lin_0 = wiki.summary(lin[0])\n",
    "        except wiki.exceptions.DisambiguationError as e:\n",
    "            sum_lin_0 = wiki.summary(e.options[0])\n",
    "        try:\n",
    "            sum_lin_1 = wiki.summary(lin[1])\n",
    "        except wiki.exceptions.DisambiguationError as e:\n",
    "            sum_lin_1 = wiki.summary(e.options[0])\n",
    "        lin_0_wiki = len(re.findall(lin[2], sum_lin_0))\n",
    "        lin_1_wiki = len(re.findall(lin[2], sum_lin_1))\n",
    "        \n",
    "        syns0 = wordnet.synsets(lin[0])\n",
    "        syns1 = wordnet.synsets(lin[1])\n",
    "        syns2 = wordnet.synsets(lin[2])\n",
    "        first_wn = wn_similarity(syns0, syns2)\n",
    "        second_wn = wn_similarity(syns1, syns2)\n",
    "        between_themselves_wn = wn_similarity(syns0, syns1)\n",
    "                \n",
    "        X.append((target_sim, comp_sim, target_sim-comp_sim, targ_comp_sim, lin_0_wiki, lin_1_wiki, lin_0_wiki-lin_1_wiki, first_wn, second_wn, between_themselves_wn))\n",
    "        y.append(lin[3])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691\n"
     ]
    }
   ],
   "source": [
    "print (len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[0:1691]\n",
    "y_train = y[0:1691]\n",
    "X_test = X[1691:]\n",
    "y_test = y[1691:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.70       508\n",
      "          1       0.69      0.70      0.69       492\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wv-wk\n",
    "neigh = KNeighborsClassifier(n_neighbors=20, p=1)\n",
    "neigh.fit(K_train, m_train)\n",
    "\n",
    "predictions = neigh.predict(K_test)\n",
    "print(classification_report(m_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.65      0.65       508\n",
      "          1       0.64      0.64      0.64       492\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#+wordnet\n",
    "neigh = KNeighborsClassifier(n_neighbors=20, p=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "predictions = neigh.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.65      0.69       508\n",
      "          1       0.67      0.75      0.71       492\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wv_wk\n",
    "ran_for = RandomForestClassifier(n_estimators=15, \n",
    "                                 max_features=None, random_state=42, max_depth=5)\n",
    "ran_for.fit(K_train, m_train)\n",
    "\n",
    "predictions = ran_for.predict(K_test)\n",
    "print(classification_report(m_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.64      0.69       508\n",
      "          1       0.67      0.76      0.71       492\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#+wordnet\n",
    "ran_for = RandomForestClassifier(n_estimators=15, \n",
    "                                 max_features=None, random_state=42, max_depth=5)\n",
    "ran_for.fit(X_train, y_train)\n",
    "\n",
    "predictions = ran_for.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
