{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = open(\"C:/Users/1/Desktop/de.txt\", \"r\", encoding=\"utf-8\")\n",
    "s = s.read()\n",
    "if '\\xad' in s:\n",
    "    s = s.replace(\"\\xad\", \"\")\n",
    "documents = s.split(\"\\n\\n \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text collection size and median length in symbols:\n",
      "1439 8027.0\n"
     ]
    }
   ],
   "source": [
    "print('Text collection size and median length in symbols:')\n",
    "print(len(documents), np.median([len(d) for d in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "stop_words = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_doc(word, translator, stop_words):\n",
    "    word = word.translate(translator)\n",
    "    word = word.lower()\n",
    "    if word not in stop_words:\n",
    "        return(word)\n",
    "        \n",
    "documents_preprocessed = []\n",
    "for doc in documents:\n",
    "    doc = doc.split()\n",
    "    doc_new = []\n",
    "    for word_doc in doc:\n",
    "        if preprocess_doc(word_doc, translator, stop_words) != None:\n",
    "            doc_new.append(preprocess_doc(word_doc, translator, stop_words))\n",
    "    doc_new = \" \".join(doc_new)\n",
    "    documents_preprocessed.append(doc_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8,\n",
    "                                   min_df=5)\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents_preprocessed)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF doc-topic shape: (1439, 10)\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "nmf = NMF(n_topics)\n",
    "nmf_doc_topic = nmf.fit_transform(tfidf)\n",
    "print('NMF doc-topic shape:', nmf_doc_topic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.8,\n",
    "                                min_df=5)\n",
    "tf = tf_vectorizer.fit_transform(documents_preprocessed)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA doc-topic shape: (1439, 10)\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics)\n",
    "lda_doc_topic = lda.fit_transform(tf)\n",
    "print('LDA doc-topic shape:', lda_doc_topic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NMF top terms:\n",
      "Topic 0:\n",
      "unternehmen, müssen, gesellschaft, brauchen, wirtschaft, gibt, politik, arbeit, muß, bürger\n",
      "Topic 1:\n",
      "europa, europäischen, europäische, union, europas, verfassung, mitgliedstaaten, staaten, europäer, bürger\n",
      "Topic 2:\n",
      "juden, geschichte, leben, israel, jüdische, christen, erinnerung, kirche, jüdischen, opfer\n",
      "Topic 3:\n",
      "afrika, afrikanischen, afrikas, afrikanische, partnerschaft, kontinent, armut, afrikaner, entwicklung, müssen\n",
      "Topic 4:\n",
      "wissenschaft, forschung, hochschulen, wissenschaftlichen, wissenschaftler, universität, universitäten, wissenschaftliche, wissenschaftsrat, wissenschaften\n",
      "Topic 5:\n",
      "kinder, schulen, schule, bildung, lehrer, schüler, eltern, lernen, müssen, brauchen\n",
      "Topic 6:\n",
      "japan, beziehungen, deutsche, china, präsident, land, zusammenarbeit, mexiko, indien, länder\n",
      "Topic 7:\n",
      "kunst, musik, kultur, ganz, frau, abend, herr, theater, lieber, schloss\n",
      "Topic 8:\n",
      "polen, polnischen, deutschpolnischen, deutschpolnische, deutschen, deutsche, polnische, nachbarn, polens, europa\n",
      "Topic 9:\n",
      "bundeswehr, soldaten, soldatinnen, streitkräfte, einsatz, dienst, wehrpflicht, afghanistan, armee, sicherheit\n",
      "\n",
      "LDA top terms:\n",
      "Topic 0:\n",
      "japan, china, indien, asien, korea, japanischen, beziehungen, japanische, indischen, asiatischen\n",
      "Topic 1:\n",
      "wissenschaft, forschung, wissenschaftlichen, orden, wissenschaftler, wissenschaften, akademie, einstein, wissenschaftliche, geisteswissenschaften\n",
      "Topic 2:\n",
      "afrika, welt, zusammenarbeit, entwicklung, müssen, nationen, staaten, europa, länder, union\n",
      "Topic 3:\n",
      "leben, geschichte, wurde, deutschen, juden, erinnerung, wurden, damals, zeit, ddr\n",
      "Topic 4:\n",
      "europa, welt, deutschen, land, ganz, gibt, müssen, europäischen, deutsche, dafür\n",
      "Topic 5:\n",
      "müssen, gesellschaft, brauchen, gibt, schon, unternehmen, dafür, bildung, wissen, geht\n",
      "Topic 6:\n",
      "sport, fußball, gesellschaft, olympischen, spiele, behinderung, mannschaft, ganz, sports, spielen\n",
      "Topic 7:\n",
      "deutschen, unserer, schon, welt, deutsche, europa, zukunft, geschichte, müssen, land\n",
      "Topic 8:\n",
      "indiz, müssen, muß, wirtschaft, unternehmen, schon, lassen, ganz, neue, welt\n",
      "Topic 9:\n",
      "majestät, spanien, frankreich, deutschfranzösische, deutschfranzösischen, venezuela, niederlande, aachen, karls, spanische\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "print('\\nNMF top terms:')\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "print('\\nLDA top terms:')\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "tok_collection = []\n",
    "for d in documents_preprocessed:\n",
    "    tok_collection.append([w for w in re.split('[\\W]+', d) if len(w) > 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tok_collection)\n",
    "corpus = [dictionary.doc2bow(text) for text in tok_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.005*\"menschen\" + 0.004*\"müssen\" + 0.004*\"heute\" + 0.003*\"immer\" + '\n",
      "  '0.003*\"deutschland\" + 0.003*\"schon\" + 0.003*\"jahren\" + 0.003*\"zukunft\" + '\n",
      "  '0.002*\"unserer\" + 0.002*\"viele\"'),\n",
      " (1,\n",
      "  '0.006*\"menschen\" + 0.006*\"deutschland\" + 0.006*\"immer\" + 0.005*\"heute\" + '\n",
      "  '0.005*\"viele\" + 0.005*\"müssen\" + 0.004*\"schon\" + 0.003*\"deutschen\" + '\n",
      "  '0.003*\"unserer\" + 0.003*\"deutsche\"'),\n",
      " (2,\n",
      "  '0.009*\"menschen\" + 0.007*\"heute\" + 0.006*\"deutschland\" + 0.004*\"immer\" + '\n",
      "  '0.004*\"deutschen\" + 0.004*\"dafür\" + 0.003*\"müssen\" + 0.003*\"gesellschaft\" + '\n",
      "  '0.003*\"viele\" + 0.003*\"gerade\"'),\n",
      " (3,\n",
      "  '0.006*\"menschen\" + 0.006*\"heute\" + 0.006*\"deutschland\" + 0.005*\"immer\" + '\n",
      "  '0.004*\"viele\" + 0.004*\"deutschen\" + 0.003*\"schon\" + 0.003*\"müssen\" + '\n",
      "  '0.003*\"leben\" + 0.003*\"jahren\"'),\n",
      " (4,\n",
      "  '0.008*\"menschen\" + 0.008*\"deutschland\" + 0.006*\"müssen\" + 0.005*\"heute\" + '\n",
      "  '0.005*\"immer\" + 0.004*\"deutschen\" + 0.004*\"viele\" + 0.003*\"dafür\" + '\n",
      "  '0.003*\"europa\" + 0.003*\"zukunft\"'),\n",
      " (5,\n",
      "  '0.006*\"heute\" + 0.006*\"immer\" + 0.006*\"menschen\" + 0.005*\"deutschland\" + '\n",
      "  '0.004*\"viele\" + 0.004*\"müssen\" + 0.004*\"europa\" + 0.003*\"dafür\" + '\n",
      "  '0.003*\"schon\" + 0.003*\"deutschen\"'),\n",
      " (6,\n",
      "  '0.009*\"menschen\" + 0.007*\"immer\" + 0.007*\"heute\" + 0.006*\"deutschland\" + '\n",
      "  '0.005*\"viele\" + 0.004*\"müssen\" + 0.004*\"schon\" + 0.004*\"leben\" + '\n",
      "  '0.003*\"jahren\" + 0.003*\"dafür\"'),\n",
      " (7,\n",
      "  '0.005*\"menschen\" + 0.005*\"deutschland\" + 0.005*\"heute\" + 0.004*\"immer\" + '\n",
      "  '0.004*\"viele\" + 0.004*\"dafür\" + 0.003*\"müssen\" + 0.003*\"schon\" + '\n",
      "  '0.003*\"europa\" + 0.003*\"deutschen\"'),\n",
      " (8,\n",
      "  '0.008*\"menschen\" + 0.006*\"heute\" + 0.005*\"müssen\" + 0.005*\"immer\" + '\n",
      "  '0.005*\"viele\" + 0.005*\"deutschland\" + 0.004*\"leben\" + 0.004*\"deutschen\" + '\n",
      "  '0.003*\"schon\" + 0.003*\"dafür\"'),\n",
      " (9,\n",
      "  '0.009*\"deutschland\" + 0.008*\"heute\" + 0.007*\"menschen\" + 0.004*\"müssen\" + '\n",
      "  '0.004*\"deutschen\" + 0.004*\"immer\" + 0.003*\"europa\" + 0.003*\"gesellschaft\" + '\n",
      "  '0.003*\"leben\" + 0.003*\"deutsche\"')]\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           num_topics=n_topics,\n",
    "                                           id2word=dictionary)\n",
    "pprint(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF top terms: наиболее релевантные результаты.\n",
    "Доделать: лемматизация (!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
