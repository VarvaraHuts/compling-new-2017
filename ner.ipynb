{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER model on CoNLL 2003 data  \n",
    "https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system.\n",
    "F-Score: 0.8396.\n",
    "Let's see whether deleting stop-words and punctuation could improve F-Score result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = open(\"C:/Users/1/Desktop/eng.train.txt\", \"r\", encoding=\"utf-8\")\n",
    "z = open(\"C:/Users/1/Desktop/eng.testa.txt\", \"r\", encoding=\"utf-8\")\n",
    "v = open(\"C:/Users/1/Desktop/eng.testb.txt\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sents(file):\n",
    "    file = file.read()\n",
    "    sents = file.split('\\n\\n')\n",
    "    arr = []\n",
    "    for sent in sents:\n",
    "        lines = sent.split(\"\\n\")\n",
    "        arr_lines = []\n",
    "        for line in lines:\n",
    "            tokens = line.split(\" \")\n",
    "            del tokens[2]\n",
    "            tokens = tuple(tokens)\n",
    "            arr_lines.append(tokens)\n",
    "        arr.append(arr_lines)\n",
    "    return (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sents = get_sents(s)\n",
    "test_sent_a = get_sents(z)\n",
    "test_sent_b = get_sents(v)\n",
    "test_sents = test_sent_a + test_sent_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP', 'I-ORG'),\n",
       " ('rejects', 'VBZ', 'O'),\n",
       " ('German', 'JJ', 'I-MISC'),\n",
       " ('call', 'NN', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('boycott', 'VB', 'O'),\n",
       " ('British', 'JJ', 'I-MISC'),\n",
       " ('lamb', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],    \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83959623980977693"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.000     0.000     0.000         6\n",
      "      I-LOC      0.873     0.808     0.839      4013\n",
      "     B-MISC      0.500     0.154     0.235        13\n",
      "     I-MISC      0.834     0.782     0.807      2173\n",
      "      B-ORG      0.000     0.000     0.000         5\n",
      "      I-ORG      0.798     0.780     0.789      4583\n",
      "      I-PER      0.881     0.907     0.894      5922\n",
      "\n",
      "avg / total      0.849     0.831     0.840     16715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "O      -> O       4.275360\n",
      "I-ORG  -> I-ORG   3.769444\n",
      "B-ORG  -> B-ORG   3.408064\n",
      "I-MISC -> B-MISC  2.868010\n",
      "I-PER  -> I-PER   2.311753\n",
      "I-MISC -> I-MISC  2.241533\n",
      "I-LOC  -> I-LOC   2.239393\n",
      "I-LOC  -> B-LOC   2.121518\n",
      "O      -> I-PER   1.204007\n",
      "I-ORG  -> O       1.097261\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-MISC -> I-PER   -2.323036\n",
      "I-ORG  -> I-MISC  -2.449459\n",
      "I-MISC -> I-LOC   -3.124988\n",
      "I-PER  -> I-LOC   -3.270511\n",
      "I-LOC  -> I-ORG   -3.571491\n",
      "I-PER  -> I-MISC  -3.645297\n",
      "I-ORG  -> I-PER   -3.724477\n",
      "I-PER  -> I-ORG   -4.213237\n",
      "I-ORG  -> I-LOC   -4.418433\n",
      "I-LOC  -> I-PER   -4.464769\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(10))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "7.126838 O        word.lower():minister\n",
      "6.232585 I-LOC    +1:word.lower():1996-08-26\n",
      "5.846777 I-ORG    -1:word.lower():v\n",
      "5.846448 I-LOC    +1:word.lower():1996-08-27\n",
      "5.743065 I-LOC    +1:word.lower():1996-08-25\n",
      "5.611029 I-LOC    +1:word.lower():1996-08-23\n",
      "5.449491 I-LOC    -1:word.lower():wisc\n",
      "5.438845 I-MISC   word.lower():frenchman\n",
      "5.413254 I-PER    word.lower():clinton\n",
      "5.273166 I-LOC    +1:word.lower():1996-08-28\n",
      "\n",
      "Top negative:\n",
      "-2.611683 O        word.lower():serie\n",
      "-2.616193 O        -1:word.lower():beat\n",
      "-2.671363 I-PER    word[-3:]:ion\n",
      "-2.833813 O        +1:word.lower():radio\n",
      "-2.881788 I-MISC   -1:word.lower():french\n",
      "-2.989782 O        -1:word.lower():moody\n",
      "-3.074463 O        -1:word.lower():queen\n",
      "-3.448288 O        word.isupper()\n",
      "-4.130953 O        -1:word.lower():lloyd\n",
      "-4.648834 O        word.istitle()\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(10))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_new = []\n",
    "for item in stop:\n",
    "    stop_new.append(item)\n",
    "    item_cap = item.replace(item[0], item[0].capitalize(), 1)\n",
    "    stop_new.append(item_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punct = []\n",
    "for item in string.punctuation:\n",
    "    punct.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = open(\"C:/Users/1/Desktop/eng.train.txt\", \"r\", encoding=\"utf-8\")\n",
    "z = open(\"C:/Users/1/Desktop/eng.testa.txt\", \"r\", encoding=\"utf-8\")\n",
    "v = open(\"C:/Users/1/Desktop/eng.testb.txt\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sents_no_stops_and_punct(file):\n",
    "    file = file.read()\n",
    "    sents = file.split('\\n\\n')\n",
    "    arr = []\n",
    "    for sent in sents:\n",
    "        lines = sent.split(\"\\n\")\n",
    "        arr_lines = []\n",
    "        for line in lines:\n",
    "            tokens = line.split(\" \")\n",
    "            del tokens[2]\n",
    "            if tokens[0] not in stop_new and tokens[0] not in punct:\n",
    "                tokens = tuple(tokens)\n",
    "                arr_lines.append(tokens)\n",
    "        arr.append(arr_lines)\n",
    "    return (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = get_sents_no_stops_and_punct(s)\n",
    "test_sent_a = get_sents_no_stops_and_punct(z)\n",
    "test_sent_b = get_sents_no_stops_and_punct(v)\n",
    "test_sents = test_sent_a + test_sent_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP', 'I-ORG'),\n",
       " ('rejects', 'VBZ', 'O'),\n",
       " ('German', 'JJ', 'I-MISC'),\n",
       " ('call', 'NN', 'O'),\n",
       " ('boycott', 'VB', 'O'),\n",
       " ('British', 'JJ', 'I-MISC'),\n",
       " ('lamb', 'NN', 'O')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72614932739151983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, stop words and punctuation are really important features for our model.\n",
    "Adding 'word[-4:]' feature (for common suffixes like -ment or -ness) did not change the results.\n",
    "\n",
    "Interestingly, some dates like '1996-08-26' or '1996-08-27' were mentioned quite often in the corpus, and the model has learnt that if the next word is '1996-08-26' etc., it is likely that the token means location or a part of location ('BRUSSELS', 'NEW YORK' etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
